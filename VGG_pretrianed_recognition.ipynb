{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50eeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import models , transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\"\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # 使用 Tkinter 支持的后端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e22176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 1.12.1+cu113\n",
      "torchvision version 0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "#版本信息\n",
    "print(f'pytorch version {torch.__version__}') ; print(f'torchvision version {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44bd6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用GPU\n",
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() > i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a59af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\douhaunmin\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\douhaunmin\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_pretrained = True\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cdef49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对图片进行预处理\n",
    "class BaseTransform():\n",
    "    def __init__(self , resize , mean , std):\n",
    "        self.basetransforms = transforms.Compose([\n",
    "            transforms.Resize(resize) , # 较短的边为resize的大小 ， 较长边根据宽高比调整\n",
    "            transforms.CenterCrop(resize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean , std)\n",
    "        ])\n",
    "    def __call__(self , img):\n",
    "        return self.basetransforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d6dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../Downloads/pytorch_advanced-master/1_image_classification/data/goldenretriever-3724972_640.jpg\"\n",
    "ILSVRC_class_index = json.load(open(\"../Downloads/pytorch_advanced-master/1_image_classification/data/imagenet_class_index.json\" , \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e4c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path) ; plt.imshow(img) ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975c844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像处理\n",
    "resize , mean , std = 224 , (0.485 , 0.456 , 0.406) , (0.229 , 0.224 , 0.225)\n",
    "transform = BaseTransform(resize , mean , std)\n",
    "img_transform = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8a8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transformed = img_transform.numpy().transpose((1 , 2 , 0))\n",
    "img_transformed = np.clip(img_transformed , 0 , 1)\n",
    "plt.imshow(img_transformed) ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259720e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "class ILSVRCPredictor():\n",
    "    def __init__(self,  class_index):\n",
    "        self.class_index = class_index\n",
    "    def predict_max(self , out):\n",
    "        maxid = np.argmax(out.detach().numpy())\n",
    "        predict_label_name = self.class_index[str(maxid)][1]\n",
    "        return predict_label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c8757be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ILSVRCPredictor(ILSVRC_class_index)\n",
    "inputs = img_transform.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1006a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golden_retriever\n"
     ]
    }
   ],
   "source": [
    "out = net(inputs)\n",
    "result = predictor.predict_max(out)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f7b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D2l_env",
   "language": "python",
   "name": "douhuanmin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
